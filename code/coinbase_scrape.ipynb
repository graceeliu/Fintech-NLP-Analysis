{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_store_scraper import AppStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.3\n",
      "  Using cached numpy-1.24.3.tar.gz (10.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[33 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 137, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     backend = _build_backend()\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 70, in _build_backend\n",
      "  \u001b[31m   \u001b[0m     obj = import_module(mod_path)\n",
      "  \u001b[31m   \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "  \u001b[31m   \u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wd/8brrldkx0rxfgw1ndw4l18yh0000gn/T/pip-build-env-hmd_ww34/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 16, in <module>\n",
      "  \u001b[31m   \u001b[0m     import setuptools.version\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wd/8brrldkx0rxfgw1ndw4l18yh0000gn/T/pip-build-env-hmd_ww34/overlay/lib/python3.12/site-packages/setuptools/version.py\", line 1, in <module>\n",
      "  \u001b[31m   \u001b[0m     import pkg_resources\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/wd/8brrldkx0rxfgw1ndw4l18yh0000gn/T/pip-build-env-hmd_ww34/overlay/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 2172, in <module>\n",
      "  \u001b[31m   \u001b[0m     register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:46:04,885 [INFO] Base - Initialised: AppStore('us', 'coinbase-buy-btc-eth-sol', 886427730)\n",
      "2025-04-24 15:46:04,886 [INFO] Base - Ready to fetch reviews from: https://apps.apple.com/us/app/coinbase-buy-btc-eth-sol/id886427730\n",
      "2025-04-24 15:46:04,993 [ERROR] Base - Something went wrong: Expecting value: line 1 column 1 (char 0)\n",
      "2025-04-24 15:46:04,993 [INFO] Base - [id:886427730] Fetched 0 reviews (0 fetched in total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install numpy==1.24.3\n",
    "import numpy as np\n",
    "\n",
    "from app_store_web_scraper import AppStoreEntry\n",
    "\n",
    "data = AppStore(country='us', app_name='Coinbase: Buy BTC, ETH, SOL', app_id = '886427730')\n",
    "data.review(how_many=1000)\n",
    "data.reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coinbase = pd.DataFrame(np.array(data.reviews),columns=['review'])\n",
    "coinbase_df= coinbase.join(pd.DataFrame(coinbase.pop('review').tolist()))\n",
    "coinbase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_filepath = '/Users/graceliu/Desktop/Columbia/Spring 2025/NLP/final_project/coinbase_reviews.csv'\n",
    "# coinbase_df.to_csv(save_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'review'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'review'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     data_clean_t \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^A-Za-z\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, str_in)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_clean_t\n\u001b[0;32m----> 8\u001b[0m coinbase_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m coinbase_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_text)\n\u001b[1;32m      9\u001b[0m coinbase_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'review'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(str_in):\n",
    "    str_in = str_in.replace(\"’\", \"'\")\n",
    "    data_clean_t = re.sub(\"[^A-Za-z']+\", \" \", str_in).strip().lower()\n",
    "    return data_clean_t\n",
    "\n",
    "coinbase_df['review'] = coinbase_df['review'].apply(clean_text)\n",
    "coinbase_df.head(10)\n",
    "# save_clean_filepath = '/Users/graceliu/Desktop/Columbia/Spring 2025/NLP/final_project/coinbase_reviews_cleaned.csv'\n",
    "# coinbase_df.to_csv(save_clean_filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/graceliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def rem_sw(str_in):\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    token_fun = str_in.split()\n",
    "    ar = list()\n",
    "    for word in token_fun:\n",
    "        if word not in sw:\n",
    "            ar.append(word)\n",
    "    ar = \" \".join(ar)\n",
    "    return ar\n",
    "\n",
    "coinbase_df['review'] = coinbase_df['review'].apply(rem_sw)\n",
    "save_clean_filepath = '/Users/graceliu/Desktop/Columbia/Spring 2025/NLP/final_project/coinbase_reviews_cleaned.csv'\n",
    "coinbase_df.to_csv(save_clean_filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>developerResponse</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>isEdited</th>\n",
       "      <th>userName</th>\n",
       "      <th>title</th>\n",
       "      <th>ml_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-11 01:28:16</td>\n",
       "      <td>{'id': 25674719, 'body': 'Hi there, thank you ...</td>\n",
       "      <td>impressed easy app use endless amounts informa...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>dank0116</td>\n",
       "      <td>Easy money !</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-23 03:06:29</td>\n",
       "      <td>{'id': 49919909, 'body': 'Hi there, Stevenra14...</td>\n",
       "      <td>really good app crypto beginners intermediate ...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Stevenra14</td>\n",
       "      <td>Great app, but missing a few key things…</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-22 02:53:25</td>\n",
       "      <td>{'id': 47669014, 'body': 'Hello Robinhoodallda...</td>\n",
       "      <td>use coinbase three years happy service halfway...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Robinhoodallday</td>\n",
       "      <td>Used for years but has gone to crap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-11 20:08:17</td>\n",
       "      <td>{'id': 48168788, 'body': 'Hi CPG Tiberius, we'...</td>\n",
       "      <td>absolutely mind boggling unhelpful circular cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>CPG Tiberius</td>\n",
       "      <td>Worst Customer Support</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-12 14:35:28</td>\n",
       "      <td>{'id': 51660061, 'body': 'Hi Usjnendin, we’re ...</td>\n",
       "      <td>left coinbase years ago kept removing payment ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Usjnendin</td>\n",
       "      <td>Holding Money Hostage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                  developerResponse  \\\n",
       "0 2021-10-11 01:28:16  {'id': 25674719, 'body': 'Hi there, thank you ...   \n",
       "1 2025-01-23 03:06:29  {'id': 49919909, 'body': 'Hi there, Stevenra14...   \n",
       "2 2024-10-22 02:53:25  {'id': 47669014, 'body': 'Hello Robinhoodallda...   \n",
       "3 2024-11-11 20:08:17  {'id': 48168788, 'body': 'Hi CPG Tiberius, we'...   \n",
       "4 2025-04-12 14:35:28  {'id': 51660061, 'body': 'Hi Usjnendin, we’re ...   \n",
       "\n",
       "                                              review  rating  isEdited  \\\n",
       "0  impressed easy app use endless amounts informa...       5     False   \n",
       "1  really good app crypto beginners intermediate ...       4     False   \n",
       "2  use coinbase three years happy service halfway...       1     False   \n",
       "3  absolutely mind boggling unhelpful circular cu...       1     False   \n",
       "4  left coinbase years ago kept removing payment ...       1      True   \n",
       "\n",
       "          userName                                     title  ml_rating  \n",
       "0         dank0116                              Easy money !          5  \n",
       "1       Stevenra14  Great app, but missing a few key things…          4  \n",
       "2  Robinhoodallday       Used for years but has gone to crap          1  \n",
       "3     CPG Tiberius                    Worst Customer Support          1  \n",
       "4        Usjnendin                     Holding Money Hostage          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coinbase_df['review'] = coinbase_df['review'].astype(str)\n",
    "coinbase_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most frequent words and most frequent rare words visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-783dfb59524f42cd9a864f7cd1ed17bd.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-783dfb59524f42cd9a864f7cd1ed17bd.vega-embed details,\n",
       "  #altair-viz-783dfb59524f42cd9a864f7cd1ed17bd.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-783dfb59524f42cd9a864f7cd1ed17bd\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-783dfb59524f42cd9a864f7cd1ed17bd\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-783dfb59524f42cd9a864f7cd1ed17bd\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"color\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"word_count\", \"title\": \"Count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"word\", \"sort\": \"-x\", \"title\": \"\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"white\", \"dx\": 5, \"fontSize\": 14}, \"encoding\": {\"text\": {\"field\": \"word\", \"type\": \"nominal\"}, \"x\": {\"field\": \"word_count\", \"title\": \"Count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"word\", \"sort\": \"-x\", \"title\": \"\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"color\": \"white\", \"dx\": -5, \"fontSize\": 14}, \"encoding\": {\"text\": {\"field\": \"word_count\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"word_count\", \"title\": \"Count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"word\", \"sort\": \"-x\", \"title\": \"\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-a9ac6e1b2385fc22e17ff03fa7c09a63\"}, \"title\": {\"text\": \"Most Frequent Terms Coinbase Reviews\", \"anchor\": \"middle\", \"fontSize\": 20}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-a9ac6e1b2385fc22e17ff03fa7c09a63\": [{\"word\": \"coinbase\", \"word_count\": 1555}, {\"word\": \"account\", \"word_count\": 1173}, {\"word\": \"app\", \"word_count\": 1152}, {\"word\": \"money\", \"word_count\": 953}, {\"word\": \"crypto\", \"word_count\": 760}, {\"word\": \"get\", \"word_count\": 603}, {\"word\": \"support\", \"word_count\": 474}, {\"word\": \"customer\", \"word_count\": 445}, {\"word\": \"time\", \"word_count\": 440}, {\"word\": \"would\", \"word_count\": 438}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "from collections import Counter\n",
    "\n",
    "# Combine all reviews into a single string \n",
    "all_reviews_words = \" \".join(coinbase_df['review'])\n",
    "all_words = all_reviews_words.split()\n",
    "\n",
    "# Get top 10 words\n",
    "top_words = pd.DataFrame(Counter(all_words).most_common(10), columns=[\"word\", \"word_count\"])\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(top_words)\n",
    "    .mark_bar(color=\"blue\")\n",
    "    .encode(\n",
    "        x=alt.X(\"word_count:Q\", title=\"Count\"),\n",
    "        y=alt.Y(\"word:N\", sort=\"-x\", title=\"\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Word labels inside bars\n",
    "text_word = chart.mark_text(\n",
    "    align=\"left\",\n",
    "    dx=5,  # Adjust spacing inside the bar\n",
    "    color=\"white\",\n",
    "    fontSize=14\n",
    ").encode(text=\"word:N\")\n",
    "\n",
    "# Count labels to the right of bars\n",
    "text_count = chart.mark_text(\n",
    "    align=\"right\",\n",
    "    dx=-5,  # Adjust spacing\n",
    "    color=\"white\",\n",
    "    fontSize=14\n",
    ").encode(text=\"word_count:Q\")\n",
    "\n",
    "# Combine and adjust title\n",
    "final_chart = (\n",
    "    (chart + text_word + text_count)\n",
    "    .properties(\n",
    "        title=alt.TitleParams(\n",
    "            \"Most Frequent Terms Coinbase Reviews\",\n",
    "            fontSize=20,  # Larger title\n",
    "            anchor=\"middle\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^ not very helpful, can do a similar visualization to this after tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abra</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>youve</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yubikey</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zfv</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abandoned  abide   ability      able  abra  abroad  abruptly  \\\n",
       "0      0.0        0.0    0.0  0.000000  0.065094   0.0     0.0       0.0   \n",
       "1      0.0        0.0    0.0  0.078138  0.000000   0.0     0.0       0.0   \n",
       "2      0.0        0.0    0.0  0.000000  0.000000   0.0     0.0       0.0   \n",
       "3      0.0        0.0    0.0  0.000000  0.000000   0.0     0.0       0.0   \n",
       "4      0.0        0.0    0.0  0.000000  0.054767   0.0     0.0       0.0   \n",
       "\n",
       "   absent  absolute  ...  youve  yrs  yubikey  yup      zero  zeros  zfv  \\\n",
       "0     0.0   0.00000  ...    0.0  0.0      0.0  0.0  0.000000    0.0  0.0   \n",
       "1     0.0   0.00000  ...    0.0  0.0      0.0  0.0  0.000000    0.0  0.0   \n",
       "2     0.0   0.00000  ...    0.0  0.0      0.0  0.0  0.079917    0.0  0.0   \n",
       "3     0.0   0.09234  ...    0.0  0.0      0.0  0.0  0.070013    0.0  0.0   \n",
       "4     0.0   0.00000  ...    0.0  0.0      0.0  0.0  0.000000    0.0  0.0   \n",
       "\n",
       "   zodiac  zoom  zooming  \n",
       "0     0.0   0.0      0.0  \n",
       "1     0.0   0.0      0.0  \n",
       "2     0.0   0.0      0.0  \n",
       "3     0.0   0.0      0.0  \n",
       "4     0.0   0.0      0.0  \n",
       "\n",
       "[5 rows x 6109 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def compute_tfidf(df, text_col, min_n=1, max_n=1):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(min_n, max_n), stop_words = 'english')\n",
    "\n",
    "    # Fit and transform the review text\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[text_col])\n",
    "\n",
    "    # Create DataFrame with feature names\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    return tfidf_df\n",
    "\n",
    "tfidf_reviews = compute_tfidf(coinbase_df, text_col='review', min_n=1, max_n=1)\n",
    "tfidf_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d8254167776d4f4bb3a0b72299013da6.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d8254167776d4f4bb3a0b72299013da6.vega-embed details,\n",
       "  #altair-viz-d8254167776d4f4bb3a0b72299013da6.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d8254167776d4f4bb3a0b72299013da6\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d8254167776d4f4bb3a0b72299013da6\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d8254167776d4f4bb3a0b72299013da6\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"color\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"avg_tfidf\", \"title\": \"Average TF-IDF Score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"word\", \"sort\": \"-x\", \"title\": \"\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"white\", \"dx\": 5, \"fontSize\": 14}, \"encoding\": {\"text\": {\"field\": \"word\", \"type\": \"nominal\"}, \"x\": {\"field\": \"avg_tfidf\", \"title\": \"Average TF-IDF Score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"word\", \"sort\": \"-x\", \"title\": \"\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"color\": \"white\", \"dx\": -5, \"fontSize\": 14}, \"encoding\": {\"text\": {\"field\": \"avg_tfidf\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"avg_tfidf\", \"title\": \"Average TF-IDF Score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"word\", \"sort\": \"-x\", \"title\": \"\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-8a1b01d509d5e98b3b646e2d40180569\"}, \"title\": {\"text\": \"Top 10 Terms by TF-IDF Score in Coinbase Reviews\", \"anchor\": \"middle\", \"fontSize\": 20}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-8a1b01d509d5e98b3b646e2d40180569\": [{\"word\": \"coinbase\", \"avg_tfidf\": 0.054697247632863225}, {\"word\": \"account\", \"avg_tfidf\": 0.05287956995489678}, {\"word\": \"app\", \"avg_tfidf\": 0.04806645772484813}, {\"word\": \"money\", \"avg_tfidf\": 0.04433458371062995}, {\"word\": \"crypto\", \"avg_tfidf\": 0.03712656314032459}, {\"word\": \"support\", \"avg_tfidf\": 0.02707742499087341}, {\"word\": \"bank\", \"avg_tfidf\": 0.026464997075799912}, {\"word\": \"customer\", \"avg_tfidf\": 0.025216105525637238}, {\"word\": \"use\", \"avg_tfidf\": 0.02393784993845896}, {\"word\": \"fees\", \"avg_tfidf\": 0.02389507156214131}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf = tfidf_reviews.mean().sort_values(ascending=False).head(10)\n",
    "top_tfidf_df = avg_tfidf.reset_index()\n",
    "top_tfidf_df.columns = ['word', 'avg_tfidf']\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(top_tfidf_df)\n",
    "    .mark_bar(color=\"blue\")\n",
    "    .encode(\n",
    "        x=alt.X(\"avg_tfidf:Q\", title=\"Average TF-IDF Score\"),\n",
    "        y=alt.Y(\"word:N\", sort=\"-x\", title=\"\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Word labels inside bars\n",
    "text_word = chart.mark_text(\n",
    "    align=\"left\",\n",
    "    dx=5,\n",
    "    color=\"white\",\n",
    "    fontSize=14\n",
    ").encode(text=\"word:N\")\n",
    "\n",
    "# Score labels to the right of bars\n",
    "text_score = chart.mark_text(\n",
    "    align=\"right\",\n",
    "    dx=-5,\n",
    "    color=\"white\",\n",
    "    fontSize=14\n",
    ").encode(text=\"avg_tfidf:Q\")\n",
    "\n",
    "# Combine layers and title\n",
    "final_chart = (\n",
    "    (chart + text_word + text_score)\n",
    "    .properties(\n",
    "        title=alt.TitleParams(\n",
    "            \"Top 10 Terms by TF-IDF Score in Coinbase Reviews\",\n",
    "            fontSize=20,\n",
    "            anchor=\"middle\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^still not very helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (vader)\n",
    "### good for short texts and detecting polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coinbase_df['vader_scores'] = coinbase_df['review'].apply(analyzer.polarity_scores)\n",
    "coinbase_df[['vader_neg', 'vader_neu', 'vader_pos', 'vader_compound']] = coinbase_df['vader_scores'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>developerResponse</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>isEdited</th>\n",
       "      <th>userName</th>\n",
       "      <th>title</th>\n",
       "      <th>ml_rating</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-11 01:28:16</td>\n",
       "      <td>{'id': 25674719, 'body': 'Hi there, thank you ...</td>\n",
       "      <td>impressed easy app use endless amounts informa...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>dank0116</td>\n",
       "      <td>Easy money !</td>\n",
       "      <td>5</td>\n",
       "      <td>{'neg': 0.063, 'neu': 0.662, 'pos': 0.275, 'co...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-23 03:06:29</td>\n",
       "      <td>{'id': 49919909, 'body': 'Hi there, Stevenra14...</td>\n",
       "      <td>really good app crypto beginners intermediate ...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Stevenra14</td>\n",
       "      <td>Great app, but missing a few key things…</td>\n",
       "      <td>4</td>\n",
       "      <td>{'neg': 0.059, 'neu': 0.635, 'pos': 0.306, 'co...</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-22 02:53:25</td>\n",
       "      <td>{'id': 47669014, 'body': 'Hello Robinhoodallda...</td>\n",
       "      <td>use coinbase three years happy service halfway...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Robinhoodallday</td>\n",
       "      <td>Used for years but has gone to crap</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.057, 'neu': 0.764, 'pos': 0.179, 'co...</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-11 20:08:17</td>\n",
       "      <td>{'id': 48168788, 'body': 'Hi CPG Tiberius, we'...</td>\n",
       "      <td>absolutely mind boggling unhelpful circular cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>CPG Tiberius</td>\n",
       "      <td>Worst Customer Support</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.074, 'neu': 0.736, 'pos': 0.19, 'com...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-12 14:35:28</td>\n",
       "      <td>{'id': 51660061, 'body': 'Hi Usjnendin, we’re ...</td>\n",
       "      <td>left coinbase years ago kept removing payment ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Usjnendin</td>\n",
       "      <td>Holding Money Hostage</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.026, 'neu': 0.767, 'pos': 0.207, 'co...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.9778</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                  developerResponse  \\\n",
       "0 2021-10-11 01:28:16  {'id': 25674719, 'body': 'Hi there, thank you ...   \n",
       "1 2025-01-23 03:06:29  {'id': 49919909, 'body': 'Hi there, Stevenra14...   \n",
       "2 2024-10-22 02:53:25  {'id': 47669014, 'body': 'Hello Robinhoodallda...   \n",
       "3 2024-11-11 20:08:17  {'id': 48168788, 'body': 'Hi CPG Tiberius, we'...   \n",
       "4 2025-04-12 14:35:28  {'id': 51660061, 'body': 'Hi Usjnendin, we’re ...   \n",
       "\n",
       "                                              review  rating  isEdited  \\\n",
       "0  impressed easy app use endless amounts informa...       5     False   \n",
       "1  really good app crypto beginners intermediate ...       4     False   \n",
       "2  use coinbase three years happy service halfway...       1     False   \n",
       "3  absolutely mind boggling unhelpful circular cu...       1     False   \n",
       "4  left coinbase years ago kept removing payment ...       1      True   \n",
       "\n",
       "          userName                                     title  ml_rating  \\\n",
       "0         dank0116                              Easy money !          5   \n",
       "1       Stevenra14  Great app, but missing a few key things…          4   \n",
       "2  Robinhoodallday       Used for years but has gone to crap          1   \n",
       "3     CPG Tiberius                    Worst Customer Support          1   \n",
       "4        Usjnendin                     Holding Money Hostage          1   \n",
       "\n",
       "                                        vader_scores  vader_neg  vader_neu  \\\n",
       "0  {'neg': 0.063, 'neu': 0.662, 'pos': 0.275, 'co...      0.063      0.662   \n",
       "1  {'neg': 0.059, 'neu': 0.635, 'pos': 0.306, 'co...      0.059      0.635   \n",
       "2  {'neg': 0.057, 'neu': 0.764, 'pos': 0.179, 'co...      0.057      0.764   \n",
       "3  {'neg': 0.074, 'neu': 0.736, 'pos': 0.19, 'com...      0.074      0.736   \n",
       "4  {'neg': 0.026, 'neu': 0.767, 'pos': 0.207, 'co...      0.026      0.767   \n",
       "\n",
       "   vader_pos  vader_compound vader_sentiment  \n",
       "0      0.275          0.9717        positive  \n",
       "1      0.306          0.9888        positive  \n",
       "2      0.179          0.9517        negative  \n",
       "3      0.190          0.8542        negative  \n",
       "4      0.207          0.9778        positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_vader_sentiment(compound_score):\n",
    "    if compound_score > 0.963:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "    # elif compound_score < 0.8:\n",
    "    #     return \"negative\"\n",
    "    # else:\n",
    "    #     return \"neutral\"\n",
    "\n",
    "coinbase_df['vader_sentiment'] = coinbase_df['vader_compound'].apply(label_vader_sentiment)\n",
    "coinbase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vader_sentiment\n",
       "negative    866\n",
       "positive    134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coinbase_df['vader_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf in negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters     0.000101\n",
      "permanent      0.000101\n",
      "dialogue       0.000101\n",
      "south          0.000113\n",
      "machine        0.000113\n",
      "replay         0.000113\n",
      "border         0.000113\n",
      "ca             0.000113\n",
      "korean         0.000113\n",
      "acted          0.000113\n",
      "shift          0.000113\n",
      "neglect        0.000119\n",
      "tender         0.000119\n",
      "excessively    0.000119\n",
      "convenience    0.000119\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "neg_reviews = coinbase_df[coinbase_df['vader_sentiment'] == 'negative'].copy()\n",
    "tfidf_neg = compute_tfidf(neg_reviews, 'review')\n",
    "\n",
    "neg_rare_words = tfidf_neg.mean().sort_values().head(15)\n",
    "neg_rare_words.columns = ['word', 'avg_tfidf']\n",
    "print(neg_rare_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doesn't tell us much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coinbase</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>account</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>money</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crypto</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>support</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>customer</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bank</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>even</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>time</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>one</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>would</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>use</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>service</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>back</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fees</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>buy</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>like</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>funds</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count\n",
       "0   coinbase   1294\n",
       "1    account   1085\n",
       "2        app    975\n",
       "3      money    871\n",
       "4     crypto    590\n",
       "5        get    542\n",
       "6    support    423\n",
       "7   customer    409\n",
       "8       bank    390\n",
       "9       even    386\n",
       "10      time    385\n",
       "11       one    369\n",
       "12     would    360\n",
       "13       use    359\n",
       "14   service    347\n",
       "15      back    337\n",
       "16      fees    310\n",
       "17       buy    307\n",
       "18      like    292\n",
       "19     funds    279"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recurring themes (most common words in neg reviews)\n",
    "all_words = \" \".join(neg_reviews['review']).split()\n",
    "word_counts = Counter(all_words)\n",
    "common_neg_words = pd.DataFrame(word_counts.most_common(20), columns=['word', 'count'])\n",
    "common_neg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer support/service, fees are pain points. \"time\" so also maybe how long the app takes to transfer funds, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA using gensim (USE THIS, not sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 17:52:29,086 [INFO] gensim.corpora.dictionary - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2025-04-18 17:52:29,107 [INFO] gensim.corpora.dictionary - built Dictionary<5716 unique tokens: ['account', 'anything', 'ask', 'aware', 'back']...> from 866 documents (total 63027 corpus positions)\n",
      "2025-04-18 17:52:29,108 [INFO] gensim.utils - Dictionary lifecycle event {'msg': \"built Dictionary<5716 unique tokens: ['account', 'anything', 'ask', 'aware', 'back']...> from 866 documents (total 63027 corpus positions)\", 'datetime': '2025-04-18T17:52:29.108214', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-14.3-arm64-arm-64bit', 'event': 'created'}\n",
      "2025-04-18 17:52:29,123 [INFO] gensim.models.ldamodel - using autotuned alpha, starting with [0.25, 0.25, 0.25, 0.25]\n",
      "2025-04-18 17:52:29,123 [INFO] gensim.models.ldamodel - using symmetric eta at 0.25\n",
      "2025-04-18 17:52:29,124 [INFO] gensim.models.ldamodel - using serial LDA version on this node\n",
      "2025-04-18 17:52:29,131 [INFO] gensim.models.ldamodel - running online (multi-pass) LDA training, 4 topics, 10 passes over the supplied corpus of 866 documents, updating model once every 866 documents, evaluating perplexity every 866 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2025-04-18 17:52:29,340 [INFO] gensim.models.ldamodel - -9.382 per-word bound, 667.2 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:29,341 [INFO] gensim.models.ldamodel - PROGRESS: pass 0, at document #866/866\n",
      "2025-04-18 17:52:29,497 [INFO] gensim.models.ldamodel - optimized alpha [0.34354436, 0.30184093, 0.35333788, 0.37471086]\n",
      "2025-04-18 17:52:29,502 [INFO] gensim.models.ldamodel - topic #0 (0.344): 0.020*\"account\" + 0.018*\"coinbase\" + 0.015*\"money\" + 0.009*\"app\" + 0.009*\"get\" + 0.008*\"bank\" + 0.007*\"back\" + 0.007*\"crypto\" + 0.006*\"days\" + 0.006*\"would\"\n",
      "2025-04-18 17:52:29,502 [INFO] gensim.models.ldamodel - topic #1 (0.302): 0.025*\"app\" + 0.012*\"crypto\" + 0.011*\"account\" + 0.008*\"even\" + 0.008*\"coinbase\" + 0.007*\"money\" + 0.007*\"one\" + 0.006*\"support\" + 0.006*\"get\" + 0.006*\"customer\"\n",
      "2025-04-18 17:52:29,502 [INFO] gensim.models.ldamodel - topic #2 (0.353): 0.021*\"coinbase\" + 0.013*\"app\" + 0.012*\"money\" + 0.011*\"account\" + 0.009*\"get\" + 0.009*\"crypto\" + 0.007*\"buy\" + 0.007*\"time\" + 0.007*\"would\" + 0.006*\"use\"\n",
      "2025-04-18 17:52:29,502 [INFO] gensim.models.ldamodel - topic #3 (0.375): 0.025*\"coinbase\" + 0.019*\"account\" + 0.015*\"money\" + 0.013*\"app\" + 0.010*\"customer\" + 0.009*\"support\" + 0.008*\"service\" + 0.008*\"crypto\" + 0.007*\"get\" + 0.006*\"bank\"\n",
      "2025-04-18 17:52:29,503 [INFO] gensim.models.ldamodel - topic diff=2.084708, rho=1.000000\n",
      "2025-04-18 17:52:29,694 [INFO] gensim.models.ldamodel - -7.487 per-word bound, 179.4 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:29,694 [INFO] gensim.models.ldamodel - PROGRESS: pass 1, at document #866/866\n",
      "2025-04-18 17:52:29,836 [INFO] gensim.models.ldamodel - optimized alpha [0.22414964, 0.15585, 0.21229398, 0.27965468]\n",
      "2025-04-18 17:52:29,837 [INFO] gensim.models.ldamodel - topic #0 (0.224): 0.020*\"account\" + 0.017*\"coinbase\" + 0.016*\"money\" + 0.009*\"bank\" + 0.009*\"app\" + 0.009*\"get\" + 0.007*\"back\" + 0.006*\"fees\" + 0.006*\"crypto\" + 0.006*\"days\"\n",
      "2025-04-18 17:52:29,837 [INFO] gensim.models.ldamodel - topic #1 (0.156): 0.028*\"app\" + 0.013*\"crypto\" + 0.009*\"account\" + 0.008*\"coinbase\" + 0.008*\"even\" + 0.007*\"one\" + 0.006*\"support\" + 0.006*\"like\" + 0.006*\"money\" + 0.006*\"use\"\n",
      "2025-04-18 17:52:29,838 [INFO] gensim.models.ldamodel - topic #2 (0.212): 0.021*\"coinbase\" + 0.014*\"app\" + 0.011*\"money\" + 0.009*\"crypto\" + 0.009*\"account\" + 0.009*\"get\" + 0.008*\"buy\" + 0.007*\"time\" + 0.007*\"would\" + 0.006*\"use\"\n",
      "2025-04-18 17:52:29,838 [INFO] gensim.models.ldamodel - topic #3 (0.280): 0.025*\"coinbase\" + 0.021*\"account\" + 0.015*\"money\" + 0.012*\"app\" + 0.011*\"customer\" + 0.009*\"support\" + 0.009*\"service\" + 0.008*\"crypto\" + 0.008*\"get\" + 0.006*\"bank\"\n",
      "2025-04-18 17:52:29,838 [INFO] gensim.models.ldamodel - topic diff=0.383724, rho=0.577350\n",
      "2025-04-18 17:52:30,011 [INFO] gensim.models.ldamodel - -7.420 per-word bound, 171.2 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:30,011 [INFO] gensim.models.ldamodel - PROGRESS: pass 2, at document #866/866\n",
      "2025-04-18 17:52:30,132 [INFO] gensim.models.ldamodel - optimized alpha [0.16147575, 0.11399106, 0.14856687, 0.21077289]\n",
      "2025-04-18 17:52:30,133 [INFO] gensim.models.ldamodel - topic #0 (0.161): 0.020*\"account\" + 0.017*\"money\" + 0.017*\"coinbase\" + 0.010*\"bank\" + 0.010*\"app\" + 0.009*\"get\" + 0.007*\"back\" + 0.007*\"fees\" + 0.006*\"days\" + 0.006*\"crypto\"\n",
      "2025-04-18 17:52:30,134 [INFO] gensim.models.ldamodel - topic #1 (0.114): 0.029*\"app\" + 0.014*\"crypto\" + 0.009*\"coinbase\" + 0.008*\"even\" + 0.007*\"account\" + 0.007*\"one\" + 0.007*\"like\" + 0.006*\"use\" + 0.006*\"support\" + 0.005*\"get\"\n",
      "2025-04-18 17:52:30,134 [INFO] gensim.models.ldamodel - topic #2 (0.149): 0.021*\"coinbase\" + 0.014*\"app\" + 0.010*\"money\" + 0.009*\"crypto\" + 0.009*\"get\" + 0.008*\"buy\" + 0.008*\"account\" + 0.007*\"time\" + 0.007*\"would\" + 0.006*\"even\"\n",
      "2025-04-18 17:52:30,134 [INFO] gensim.models.ldamodel - topic #3 (0.211): 0.025*\"coinbase\" + 0.022*\"account\" + 0.014*\"money\" + 0.012*\"customer\" + 0.011*\"app\" + 0.010*\"support\" + 0.009*\"service\" + 0.008*\"get\" + 0.008*\"crypto\" + 0.006*\"bank\"\n",
      "2025-04-18 17:52:30,134 [INFO] gensim.models.ldamodel - topic diff=0.250916, rho=0.500000\n",
      "2025-04-18 17:52:30,295 [INFO] gensim.models.ldamodel - -7.387 per-word bound, 167.4 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:30,296 [INFO] gensim.models.ldamodel - PROGRESS: pass 3, at document #866/866\n",
      "2025-04-18 17:52:30,415 [INFO] gensim.models.ldamodel - optimized alpha [0.13109612, 0.093786865, 0.118135594, 0.17615987]\n",
      "2025-04-18 17:52:30,417 [INFO] gensim.models.ldamodel - topic #0 (0.131): 0.020*\"account\" + 0.018*\"money\" + 0.016*\"coinbase\" + 0.011*\"bank\" + 0.010*\"app\" + 0.009*\"get\" + 0.008*\"back\" + 0.007*\"fees\" + 0.006*\"days\" + 0.006*\"buy\"\n",
      "2025-04-18 17:52:30,417 [INFO] gensim.models.ldamodel - topic #1 (0.094): 0.030*\"app\" + 0.014*\"crypto\" + 0.009*\"coinbase\" + 0.008*\"even\" + 0.007*\"like\" + 0.006*\"one\" + 0.006*\"account\" + 0.006*\"use\" + 0.005*\"support\" + 0.005*\"get\"\n",
      "2025-04-18 17:52:30,417 [INFO] gensim.models.ldamodel - topic #2 (0.118): 0.021*\"coinbase\" + 0.014*\"app\" + 0.010*\"money\" + 0.009*\"crypto\" + 0.008*\"get\" + 0.008*\"buy\" + 0.007*\"time\" + 0.007*\"would\" + 0.007*\"account\" + 0.006*\"even\"\n",
      "2025-04-18 17:52:30,417 [INFO] gensim.models.ldamodel - topic #3 (0.176): 0.024*\"coinbase\" + 0.023*\"account\" + 0.014*\"money\" + 0.012*\"customer\" + 0.011*\"app\" + 0.010*\"support\" + 0.009*\"service\" + 0.008*\"get\" + 0.007*\"crypto\" + 0.006*\"bank\"\n",
      "2025-04-18 17:52:30,417 [INFO] gensim.models.ldamodel - topic diff=0.167388, rho=0.447214\n",
      "2025-04-18 17:52:30,577 [INFO] gensim.models.ldamodel - -7.369 per-word bound, 165.4 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:30,578 [INFO] gensim.models.ldamodel - PROGRESS: pass 4, at document #866/866\n",
      "2025-04-18 17:52:30,683 [INFO] gensim.models.ldamodel - optimized alpha [0.11362804, 0.081518814, 0.101049624, 0.15662885]\n",
      "2025-04-18 17:52:30,684 [INFO] gensim.models.ldamodel - topic #0 (0.114): 0.019*\"account\" + 0.019*\"money\" + 0.016*\"coinbase\" + 0.011*\"bank\" + 0.010*\"app\" + 0.008*\"get\" + 0.008*\"back\" + 0.007*\"fees\" + 0.006*\"buy\" + 0.006*\"bitcoin\"\n",
      "2025-04-18 17:52:30,684 [INFO] gensim.models.ldamodel - topic #1 (0.082): 0.030*\"app\" + 0.015*\"crypto\" + 0.009*\"coinbase\" + 0.007*\"even\" + 0.007*\"like\" + 0.006*\"one\" + 0.006*\"use\" + 0.005*\"coin\" + 0.005*\"see\" + 0.005*\"account\"\n",
      "2025-04-18 17:52:30,685 [INFO] gensim.models.ldamodel - topic #2 (0.101): 0.022*\"coinbase\" + 0.014*\"app\" + 0.010*\"crypto\" + 0.010*\"money\" + 0.008*\"buy\" + 0.008*\"get\" + 0.007*\"time\" + 0.007*\"would\" + 0.006*\"even\" + 0.006*\"one\"\n",
      "2025-04-18 17:52:30,685 [INFO] gensim.models.ldamodel - topic #3 (0.157): 0.024*\"coinbase\" + 0.024*\"account\" + 0.014*\"money\" + 0.012*\"customer\" + 0.011*\"app\" + 0.010*\"support\" + 0.010*\"service\" + 0.009*\"get\" + 0.007*\"crypto\" + 0.006*\"bank\"\n",
      "2025-04-18 17:52:30,685 [INFO] gensim.models.ldamodel - topic diff=0.116743, rho=0.408248\n",
      "2025-04-18 17:52:30,841 [INFO] gensim.models.ldamodel - -7.359 per-word bound, 164.1 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:30,841 [INFO] gensim.models.ldamodel - PROGRESS: pass 5, at document #866/866\n",
      "2025-04-18 17:52:30,944 [INFO] gensim.models.ldamodel - optimized alpha [0.102390215, 0.073041305, 0.08991812, 0.1448665]\n",
      "2025-04-18 17:52:30,945 [INFO] gensim.models.ldamodel - topic #0 (0.102): 0.019*\"money\" + 0.019*\"account\" + 0.016*\"coinbase\" + 0.011*\"bank\" + 0.010*\"app\" + 0.008*\"get\" + 0.008*\"back\" + 0.008*\"fees\" + 0.007*\"buy\" + 0.007*\"bitcoin\"\n",
      "2025-04-18 17:52:30,945 [INFO] gensim.models.ldamodel - topic #1 (0.073): 0.031*\"app\" + 0.015*\"crypto\" + 0.009*\"coinbase\" + 0.007*\"like\" + 0.007*\"even\" + 0.006*\"one\" + 0.006*\"use\" + 0.006*\"see\" + 0.005*\"coin\" + 0.005*\"get\"\n",
      "2025-04-18 17:52:30,945 [INFO] gensim.models.ldamodel - topic #2 (0.090): 0.022*\"coinbase\" + 0.014*\"app\" + 0.010*\"crypto\" + 0.009*\"money\" + 0.008*\"buy\" + 0.008*\"get\" + 0.007*\"time\" + 0.007*\"would\" + 0.006*\"even\" + 0.006*\"use\"\n",
      "2025-04-18 17:52:30,945 [INFO] gensim.models.ldamodel - topic #3 (0.145): 0.024*\"account\" + 0.024*\"coinbase\" + 0.014*\"money\" + 0.012*\"customer\" + 0.010*\"support\" + 0.010*\"app\" + 0.010*\"service\" + 0.009*\"get\" + 0.007*\"crypto\" + 0.007*\"email\"\n",
      "2025-04-18 17:52:30,946 [INFO] gensim.models.ldamodel - topic diff=0.085234, rho=0.377964\n",
      "2025-04-18 17:52:31,099 [INFO] gensim.models.ldamodel - -7.351 per-word bound, 163.3 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:31,100 [INFO] gensim.models.ldamodel - PROGRESS: pass 6, at document #866/866\n",
      "2025-04-18 17:52:31,201 [INFO] gensim.models.ldamodel - optimized alpha [0.09455301, 0.06684153, 0.082017355, 0.1370969]\n",
      "2025-04-18 17:52:31,202 [INFO] gensim.models.ldamodel - topic #0 (0.095): 0.020*\"money\" + 0.019*\"account\" + 0.016*\"coinbase\" + 0.011*\"bank\" + 0.010*\"app\" + 0.008*\"get\" + 0.008*\"fees\" + 0.008*\"back\" + 0.007*\"buy\" + 0.007*\"bitcoin\"\n",
      "2025-04-18 17:52:31,202 [INFO] gensim.models.ldamodel - topic #1 (0.067): 0.031*\"app\" + 0.015*\"crypto\" + 0.009*\"coinbase\" + 0.008*\"like\" + 0.007*\"even\" + 0.006*\"one\" + 0.006*\"see\" + 0.006*\"use\" + 0.006*\"coin\" + 0.005*\"get\"\n",
      "2025-04-18 17:52:31,203 [INFO] gensim.models.ldamodel - topic #2 (0.082): 0.022*\"coinbase\" + 0.014*\"app\" + 0.010*\"crypto\" + 0.009*\"money\" + 0.008*\"buy\" + 0.007*\"get\" + 0.007*\"time\" + 0.006*\"would\" + 0.006*\"use\" + 0.006*\"even\"\n",
      "2025-04-18 17:52:31,203 [INFO] gensim.models.ldamodel - topic #3 (0.137): 0.025*\"account\" + 0.024*\"coinbase\" + 0.014*\"money\" + 0.012*\"customer\" + 0.011*\"support\" + 0.010*\"app\" + 0.010*\"service\" + 0.009*\"get\" + 0.007*\"crypto\" + 0.007*\"email\"\n",
      "2025-04-18 17:52:31,203 [INFO] gensim.models.ldamodel - topic diff=0.065076, rho=0.353553\n",
      "2025-04-18 17:52:31,354 [INFO] gensim.models.ldamodel - -7.345 per-word bound, 162.6 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:31,354 [INFO] gensim.models.ldamodel - PROGRESS: pass 7, at document #866/866\n",
      "2025-04-18 17:52:31,455 [INFO] gensim.models.ldamodel - optimized alpha [0.08869547, 0.06222324, 0.07609908, 0.1315458]\n",
      "2025-04-18 17:52:31,456 [INFO] gensim.models.ldamodel - topic #0 (0.089): 0.020*\"money\" + 0.018*\"account\" + 0.015*\"coinbase\" + 0.012*\"bank\" + 0.010*\"app\" + 0.008*\"fees\" + 0.008*\"get\" + 0.008*\"back\" + 0.007*\"buy\" + 0.007*\"bitcoin\"\n",
      "2025-04-18 17:52:31,456 [INFO] gensim.models.ldamodel - topic #1 (0.062): 0.031*\"app\" + 0.016*\"crypto\" + 0.009*\"coinbase\" + 0.008*\"like\" + 0.007*\"even\" + 0.006*\"one\" + 0.006*\"see\" + 0.006*\"use\" + 0.006*\"coin\" + 0.005*\"time\"\n",
      "2025-04-18 17:52:31,456 [INFO] gensim.models.ldamodel - topic #2 (0.076): 0.022*\"coinbase\" + 0.014*\"app\" + 0.010*\"crypto\" + 0.009*\"money\" + 0.008*\"buy\" + 0.007*\"time\" + 0.007*\"get\" + 0.006*\"would\" + 0.006*\"use\" + 0.006*\"fees\"\n",
      "2025-04-18 17:52:31,456 [INFO] gensim.models.ldamodel - topic #3 (0.132): 0.025*\"account\" + 0.024*\"coinbase\" + 0.014*\"money\" + 0.012*\"customer\" + 0.011*\"support\" + 0.010*\"app\" + 0.010*\"service\" + 0.009*\"get\" + 0.007*\"email\" + 0.007*\"crypto\"\n",
      "2025-04-18 17:52:31,457 [INFO] gensim.models.ldamodel - topic diff=0.051507, rho=0.333333\n",
      "2025-04-18 17:52:31,608 [INFO] gensim.models.ldamodel - -7.341 per-word bound, 162.1 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:31,609 [INFO] gensim.models.ldamodel - PROGRESS: pass 8, at document #866/866\n",
      "2025-04-18 17:52:31,708 [INFO] gensim.models.ldamodel - optimized alpha [0.084199525, 0.058527526, 0.07152305, 0.12721221]\n",
      "2025-04-18 17:52:31,709 [INFO] gensim.models.ldamodel - topic #0 (0.084): 0.020*\"money\" + 0.018*\"account\" + 0.015*\"coinbase\" + 0.012*\"bank\" + 0.010*\"app\" + 0.008*\"fees\" + 0.008*\"get\" + 0.008*\"back\" + 0.007*\"buy\" + 0.007*\"bitcoin\"\n",
      "2025-04-18 17:52:31,709 [INFO] gensim.models.ldamodel - topic #1 (0.059): 0.032*\"app\" + 0.016*\"crypto\" + 0.009*\"coinbase\" + 0.008*\"like\" + 0.007*\"even\" + 0.006*\"see\" + 0.006*\"one\" + 0.006*\"use\" + 0.006*\"coin\" + 0.005*\"time\"\n",
      "2025-04-18 17:52:31,709 [INFO] gensim.models.ldamodel - topic #2 (0.072): 0.022*\"coinbase\" + 0.014*\"app\" + 0.010*\"crypto\" + 0.009*\"money\" + 0.008*\"buy\" + 0.007*\"time\" + 0.007*\"get\" + 0.006*\"would\" + 0.006*\"use\" + 0.006*\"fees\"\n",
      "2025-04-18 17:52:31,709 [INFO] gensim.models.ldamodel - topic #3 (0.127): 0.025*\"account\" + 0.024*\"coinbase\" + 0.013*\"money\" + 0.012*\"customer\" + 0.011*\"support\" + 0.010*\"app\" + 0.010*\"get\" + 0.010*\"service\" + 0.007*\"email\" + 0.007*\"crypto\"\n",
      "2025-04-18 17:52:31,709 [INFO] gensim.models.ldamodel - topic diff=0.042455, rho=0.316228\n",
      "2025-04-18 17:52:31,859 [INFO] gensim.models.ldamodel - -7.337 per-word bound, 161.7 perplexity estimate based on a held-out corpus of 866 documents with 63027 words\n",
      "2025-04-18 17:52:31,859 [INFO] gensim.models.ldamodel - PROGRESS: pass 9, at document #866/866\n",
      "2025-04-18 17:52:31,956 [INFO] gensim.models.ldamodel - optimized alpha [0.080832295, 0.055523533, 0.06782479, 0.12404086]\n",
      "2025-04-18 17:52:31,957 [INFO] gensim.models.ldamodel - topic #0 (0.081): 0.021*\"money\" + 0.018*\"account\" + 0.015*\"coinbase\" + 0.012*\"bank\" + 0.010*\"app\" + 0.009*\"fees\" + 0.008*\"back\" + 0.008*\"get\" + 0.007*\"buy\" + 0.007*\"bitcoin\"\n",
      "2025-04-18 17:52:31,957 [INFO] gensim.models.ldamodel - topic #1 (0.056): 0.032*\"app\" + 0.016*\"crypto\" + 0.009*\"coinbase\" + 0.008*\"like\" + 0.007*\"even\" + 0.006*\"see\" + 0.006*\"one\" + 0.006*\"coin\" + 0.006*\"use\" + 0.005*\"time\"\n",
      "2025-04-18 17:52:31,957 [INFO] gensim.models.ldamodel - topic #2 (0.068): 0.023*\"coinbase\" + 0.014*\"app\" + 0.010*\"crypto\" + 0.009*\"money\" + 0.008*\"buy\" + 0.007*\"time\" + 0.007*\"get\" + 0.006*\"fees\" + 0.006*\"would\" + 0.006*\"use\"\n",
      "2025-04-18 17:52:31,957 [INFO] gensim.models.ldamodel - topic #3 (0.124): 0.025*\"account\" + 0.024*\"coinbase\" + 0.013*\"money\" + 0.012*\"customer\" + 0.011*\"support\" + 0.010*\"app\" + 0.010*\"get\" + 0.010*\"service\" + 0.007*\"email\" + 0.007*\"crypto\"\n",
      "2025-04-18 17:52:31,958 [INFO] gensim.models.ldamodel - topic diff=0.035661, rho=0.301511\n",
      "2025-04-18 17:52:31,958 [INFO] gensim.utils - LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=5716, num_topics=4, decay=0.5, chunksize=2000> in 2.83s', 'datetime': '2025-04-18T17:52:31.958244', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]', 'platform': 'macOS-14.3-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: ['money', 'account', 'coinbase', 'bank', 'app', 'fees', 'back', 'get', 'buy', 'bitcoin']\n",
      "Topic 2: ['app', 'crypto', 'coinbase', 'like', 'even', 'see', 'one', 'coin', 'use', 'time']\n",
      "Topic 3: ['coinbase', 'app', 'crypto', 'money', 'buy', 'time', 'get', 'fees', 'would', 'use']\n",
      "Topic 4: ['account', 'coinbase', 'money', 'customer', 'support', 'app', 'get', 'service', 'email', 'crypto']\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenize and preprocess\n",
    "texts = [simple_preprocess(doc, deacc=True) for doc in neg_reviews['review']]\n",
    "\n",
    "# 2. Create dictionary and bag-of-words corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 3. Train LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=4,\n",
    "                     random_state=42,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)\n",
    "\n",
    "# 4. Print top words per topic\n",
    "for i, topic in lda_model.show_topics(num_topics=4, formatted=False):\n",
    "    print(f\"Topic {i+1}: {[word for word, _ in topic]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "1. customer support (also phone, email, number, access) --> complaints about not reaching customer support --> improve customer support and communication\n",
    "2. account, money --> frustration around accessing account/money --> streamline account recovery process\n",
    "3. fees --> unclear or high fees --> improve fee transparency\n",
    "4. time --> bad timing of transactions or delays --> improve reliabliity and speed of banking/crypto transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "['fees', 'time', 'customer', 'bank', 'support', 'crypto', 'money', 'app', 'coinbase', 'account']\n",
      "Topic 2:\n",
      "['jacob', 'texted', 'phantom', 'armstrong', 'blocks', 'brian', 'excites', 'temp', 'sales', 'felt']\n",
      "Topic 3:\n",
      "['bnt', 'adjust', 'homepage', 'quit', 'men', 'jeremy', 'coordinated', 'renner', 'battery', 'bonus']\n",
      "Topic 4:\n",
      "['tolerated', 'angela', 'wi', 'bless', 'brian', 'fungible', 'passcode', 'wannabe', 'sendable', 'barcodes']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(neg_reviews['review'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Top words per topic\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {i+1}:\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights from topics 1 & 2\n",
    "1. customer support (also phone, email, number, access) --> complaints about not reaching customer support --> improve customer support and communication\n",
    "2. account, money --> frustration around accessing account/money --> streamline account recovery process\n",
    "3. fees --> unclear or high fees --> improve fee transparency\n",
    "4. time --> bad timing of transactions or delays --> improve reliabliity and speed of banking/crypto transfers\n",
    "\n",
    "### Insights from topic 3: emotional cluster, likely angry reviews \n",
    "1. unimpressive, interfaces --> poor UI/UX --> simplify in-app navigation or run user/usability studies focusing on UI\n",
    "\n",
    "### nothing useful from topic 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (textblob)\n",
    "### adds subjectivity, better for longer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob \n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# '''\n",
    "# polarity: [-1.0, 1.0]:\n",
    "# - Negative = negative sentiment\n",
    "# - Positive = positive sentiment\n",
    "# - 0 = neutral\n",
    "# subjectivity: 0.0, 1.0]:\n",
    "# - Closer to 1 = opinion-based\n",
    "# - Closer to 0 = more factual/objective\n",
    "# '''\n",
    "# def add_textblob_sentiment(df, text_col):\n",
    "#     df[text_col] = df[text_col].astype(str)\n",
    "\n",
    "#     # Apply TextBlob sentiment\n",
    "#     df['textblob_polarity'] = df[text_col].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "#     df['textblob_subjectivity'] = df[text_col].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# coinbase_df_with_tb = add_textblob_sentiment(coinbase_df, 'review')\n",
    "# coinbase_df_with_tb[['review', 'textblob_polarity', 'textblob_subjectivity']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## not sure how to feel about text blob's polarity scores after cross referencing them with the original coinbase reviews and ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
